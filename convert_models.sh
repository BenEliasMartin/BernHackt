#!/bin/bash

# Convert PyTorch models to ONNX format for browser inference

echo "ğŸš€ Converting Fin-O models to ONNX format..."

# Create output directory
mkdir -p public/model

# Convert Fin-O Small model
echo "ğŸ”„ Converting Fin-O Small model..."
python3 scripts/convert_pytorch_to_onnx.py \
  --model-type small \
  --model-path model/fin-o-small \
  --output-dir public/model

# Convert Fin-O Large model  
echo "ğŸ”„ Converting Fin-O Large model..."
python3 scripts/convert_pytorch_to_onnx.py \
  --model-type large \
  --model-path model/fin-o-large \
  --output-dir public/model

echo "âœ… Model conversion complete!"
echo "ğŸ“ Files created in public/model/:"
ls -la public/model/
echo ""
echo "ğŸŒ You can now test the models at: http://localhost:3000"
